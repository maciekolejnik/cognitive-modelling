/** PART 1: Tic-tac-toe with no mental
 *  These experiments aim to show that agents with better cognitive
 *  abilities (measured by lookahead parameter) perform better in
 *  tic-tac-toe and also that agent's behaviour depends on their
 *  beliefs of opponent's lookahead
 * */
let scenarios = function() {
  let getParams = function(lookAhead) {
    return {
      /** format [physical goal, mental goal] */
      goalCoeffs: [1],
      metaParams: {
        alpha: 1000,
        discountFactor: 0.9,
        lookAhead: lookAhead
      }
    }
  }
  let getInitialState = function(agentID, lookAheadEstimation) {
    let alpha = [undefined, Delta({v: 1000})]
    let discountFactor = [undefined, Delta({v: 0.9})]
    let lookAhead = [undefined, Delta({v: lookAheadEstimation})]
    let belief = [
      Delta({v:["belief over oneself"]}),
      Delta({v:[1]})
    ]
    return {
      belief: (agentID == 0) ?
        belief : arrayReverse(belief),
      mentalEstimations : [undefined],
      metaParamsEstimations: {
        alpha: (agentID == 0) ?
          alpha : arrayReverse(alpha),
        lookAhead: (agentID == 0) ?
          lookAhead : arrayReverse(lookAhead),
        discountFactor: (agentID == 0) ?
          discountFactor : arrayReverse(discountFactor)
      }
    }
  }
  let getAgent = function(agentID, lookAhead, lookAheadEstimation) {
    return {
      params: getParams(lookAhead),
      initialState: getInitialState(agentID, lookAheadEstimation)
    }
  }

  // let params = {
  //   /** format [physical goal, mental goal] */
  //   goalCoeffs: [1],
  //   metaParams: {
  //     alpha: 1000,
  //     discountFactor: 0.9,
  //     lookAhead: 3
  //   }
  // }
  // let alpha = [undefined, Delta({v: 1000})]
  // let discountFactor = [undefined, Delta({v: 0.9})]
  // let lookAhead = [undefined, Delta({v: 3})]
  // let metaParamsEstimations = {
  //   alpha,
  //   lookAhead,
  //   discountFactor
  // }
  // let mentalEstimations = [undefined]
  // /** belief over oneself is a delta */
  // let belief = [
  //   Delta({v:["belief over oneself"]}),
  //   Delta({v:[1]})
  // ]
  // let crossAgent = {
  //   params,
  //   initialState: {
  //     belief,
  //     mentalEstimations,
  //     metaParamsEstimations: {
  //       alpha, lookAhead, discountFactor
  //     }
  //   }
  // }
  // let noughtAgent = {
  //   params,
  //   initialState: {
  //     belief: arrayReverse(belief),
  //     mentalEstimations,
  //     metaParamsEstimations: {
  //       alpha: arrayReverse(alpha),
  //       lookAhead: arrayReverse(lookAhead),
  //       discountFactor: arrayReverse(discountFactor)
  //     }
  //   }
  // }
  let result = [
    {
      name: 'strong vs strong and both think their opponent strong',
      agents:
        [
          getAgent(0, 9, 9),
          getAgent(1, 9, 9)
        ],
      options: {
        horizon: 9,
        beliefRepresentation: 'discrete'
      },
      gameSpecificParams: {
        stateRepresentation: 'efficient'
      }
    },
    {
      name: 'strong vs weak but strong thinks opponent strong',
      agents:
        [
          getAgent(0, 9, 9),
          getAgent(1, 3, 3)
        ],
      options: {
        horizon: 9,
        beliefRepresentation: 'discrete'
      },
      gameSpecificParams: {
        stateRepresentation: 'efficient'
      }
    },
    {
      name: 'strong vs weak and strong thinks opponent weak',
      agents:
        [
          getAgent(0, 9, 3),
          getAgent(1, 3, 3)
        ],
      options: {
        horizon: 9,
        beliefRepresentation: 'discrete'
      },
      gameSpecificParams: {
        stateRepresentation: 'efficient'
      }
    }
  ]
  return result
}()

let trajectories =
  simulateScenarios(scenarios, makeTicTacToe, ['cross', 'nought'])
display(arrayToString(trajectories))

