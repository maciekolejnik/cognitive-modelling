/** PART 1: Tic-tac-toe with no mental
 *  These experiments aim to show that agents with better cognitive
 *  abilities (measured by lookahead parameter) perform better in
 *  tic-tac-toe and also that agent's behaviour depends on their
 *  beliefs of opponent's lookahead
 * */
let scenarios = function() {
  let getParams = function(lookAhead) {
    return {
      /** format [physical goal, mental goal] */
      goalCoeffs: [1],
      metaParams: {
        alpha: 1000,
        discountFactor: 0.9,
        lookAhead: lookAhead
      }
    }
  }
  let getInitialState = function(agentID, lookAheadEstimation) {
    let alpha = [undefined, Delta({v: 1000})]
    let discountFactor = [undefined, Delta({v: 0.9})]
    let lookAhead = [undefined, Delta({v: lookAheadEstimation})]
    let belief = [
      Delta({v:["belief over oneself"]}),
      Delta({v:[1]})
    ]
    return {
      belief: (agentID == 0) ?
        belief : arrayReverse(belief),
      mentalEstimations : [undefined],
      metaParamsEstimations: {
        alpha: (agentID == 0) ?
          alpha : arrayReverse(alpha),
        lookAhead: (agentID == 0) ?
          lookAhead : arrayReverse(lookAhead),
        discountFactor: (agentID == 0) ?
          discountFactor : arrayReverse(discountFactor)
      }
    }
  }
  let getAgent = function(agentID, lookAhead, lookAheadEstimation) {
    return {
      params: getParams(lookAhead),
      initialState: getInitialState(agentID, lookAheadEstimation)
    }
  }

  let result = [
    {
      name: 'strong vs strong and both think their opponent strong',
      agents:
        [
          getAgent(0, 9, 9),
          getAgent(1, 9, 9)
        ],
      options: {
        horizon: 9,
        beliefRepresentation: 'discrete'
      },
      gameSpecificParams: {
        stateRepresentation: 'efficient'
      }
    },
    {
      name: 'strong vs weak but strong thinks opponent strong',
      agents:
        [
          getAgent(0, 9, 9),
          getAgent(1, 3, 3)
        ],
      options: {
        horizon: 9,
        beliefRepresentation: 'discrete'
      },
      gameSpecificParams: {
        stateRepresentation: 'efficient'
      }
    },
    {
      name: 'strong vs weak and strong thinks opponent weak',
      agents:
        [
          getAgent(0, 9, 3),
          getAgent(1, 3, 3)
        ],
      options: {
        horizon: 9,
        beliefRepresentation: 'discrete'
      },
      gameSpecificParams: {
        stateRepresentation: 'efficient'
      }
    },
    {
      name: 'weak vs weak and accurate estimations',
      agents:
        [
          getAgent(0, 3, 3),
          getAgent(1, 3, 3)
        ],
      options: {
        horizon: 9,
        beliefRepresentation: 'discrete'
      },
      gameSpecificParams: {
        stateRepresentation: 'efficient'
      }
    }
  ]
  return result
}()

// let trajectories =
//   simulateScenarios(scenarios, makeTicTacToe, ['cross', 'nought'])
// display(arrayToString(trajectories))
let final = function(game, agents, finalState, names) {
  let finalBoard = (!_top.Array.isArray(finalState[0])) ?
    finalState :
  function() {
    //convert into board
    let emptyBoard = repeat(9, getUndefined)
    return reduceL(function(board,move) {
      return arrayReplace(board, move[1], move[0])
    }, emptyBoard, finalState)
  }()
  if (threeInARow(finalBoard, 'X')) {
    display("\nwinner: X\n")
  } else if (threeInARow(finalBoard, 'O')) {
    display("\nwinner: O\n")
  } else {
    display("\ndraw\n")
  }
}

let callbacks = {
  final
}

// repeat(20, function() {simulateScenarios(scenarios.slice(3,4), makeTicTacToe, ['cross', 'nought'], callbacks)})



/** PART 2: Tic-tac-toe with mental component (parent vs kid)
 *
 * */
let scenarios2 = function() {
  let getParentParams = function(firstCoeff, lookAhead) {
    return {
      /** format [physical goal, mental goal] */
      goalCoeffs: [firstCoeff, 1 - firstCoeff],
      metaParams: {
        alpha: 100,
        discountFactor: 1,
        lookAhead: lookAhead
      }
    }
  }
  let getParentInitialState = function(lookAheadEstimation) {
    let alpha = [Delta({v: 5}), undefined]
    let discountFactor = [Delta({v: 0.9}), undefined]
    let lookAhead = [Delta({v: lookAheadEstimation}), undefined]
    let belief = [
      Delta({v:[1]}),
      Delta({v:["belief over oneself"]})
    ]
    return {
      belief,
      mentalEstimations :
        [
          [Delta({v: 0})], /** over agent 0 (kid) */
          undefined /** over oneself */
        ],
      metaParamsEstimations: {
        alpha,
        lookAhead,
        discountFactor
      }
    }
  }
  let getChildParams = function(alpha, discountFactor, lookAhead) {
    return {
      /** format [physical goal, mental goal] */
      goalCoeffs: [1],
      metaParams: {
        alpha,
        discountFactor,
        lookAhead
      }
    }
  }
  let getChildInitialState = function(lookAheadEstimation) {
    let alpha = [undefined, Delta({v: 100})]
    let discountFactor = [undefined, Delta({v: 0.9})]
    let lookAhead = [undefined, Delta({v: lookAheadEstimation})]
    let belief = [
      Delta({v:["belief over oneself"]}),
      Delta({v:[1,0]})
    ]
    return {
      belief,
      mentalEstimations : [undefined, undefined],
      metaParamsEstimations: {
        alpha,
        lookAhead,
        discountFactor
      }
    }
  }
  let getChild = function(alpha, discountFactor, lookAhead, lookAheadEstimation) {
    return {
      params: getChildParams(alpha, discountFactor, lookAhead),
      initialState: getChildInitialState(lookAheadEstimation)
    }
  }
  let getParent = function(firstCoeff, lookAhead, lookAheadEstimation) {
    return {
      params: getParentParams(firstCoeff, lookAhead),
      initialState: getParentInitialState(lookAheadEstimation)
    }
  }

  let startingState = [['X',0],['O',8],['X',4]]
  let startingState1 = [['X',2],['O',8],['X',4],['O',3],['X',0]]
  let startingState2 = [['O',7],['X',0],['O',8],['X',4]]
  let startingState3 = [['X',6],['O',7],['X',0],['O',8],['X',4]]
  let result = [
    {
      name: 'parent vs kid',
      agents:
        [
          getChild(100, 0.9, 2, 2),
          getParent(0.1, 3, 2)
        ],
      options: {
        horizon: 9,
        beliefRepresentation: 'discrete'
      },
      // startingState: startingState1,
      gameSpecificParams: {
        stateRepresentation: 'history'
      }
    },
    {
      name: 'parent vs kid from qest paper running example',
      agents:
        [
          getChild(5, 0.7, 2, 2),
          getParent(0.1, 3, 2)
        ],
      options: {
        horizon: 1,
        beliefRepresentation: 'discrete'
      },
      startingState: startingState,
      gameSpecificParams: {
        stateRepresentation: 'history'
      }
    }
  ]
  return result
}()

repeat(1, function() { simulateScenarios(scenarios2.slice(1,2), makeTicTacToe, ['kid', 'parent'], callbacks)})
