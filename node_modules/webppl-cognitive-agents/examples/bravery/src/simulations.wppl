/** To run:
 $ webppl examples/bravery/src/simulations.wppl --require . --require
 examples/bravery [--] [--help] [--experiment <experimentID>]
 [--scenario <scenarioID>] [--runs <numberOfRuns>]
 */

/* Setup game structure */
let options = {
  horizon: 20,
  beliefRepresentation: 'dirichlet'
}

/**
 * callback functions can be defined here
 */
let printBeliefs = function(game, agents, state, names) {
  display("+----------- agents' state --------------+")
  mapIndexed(function(agentID, agent) {
    let belief = agent.belief
    let indBelief = retrieveBeliefOver(otherAgentID(agentID), belief(state))
    let goalCoeffsExpectation = goalCoeffsExpectation(indBelief, 3)
    display(names[agentID] + "'s belief (expectations): " +
      toString(goalCoeffsExpectation))
  }, agents)
  let turn = game.API.turn
  if (turn(state) === 1) {
    let p2 = agents[1]
    let ms = p2.mentalState
    let pride = ms(state)[0]
    display("p2's pride: " + pride)
    let p1 = agents[0]
    let mr = p1.mentalRewards
    let prideEst = mr(state)[0]
    display("p1's pride estimation: " + prideEst)
  }
  display("+-----------      end      --------------+")
}

let callbacks = {
  periodic: printBeliefs,
}

let getScenarios = function() {
  /**
   example scenario
   */
  let getTestScenario = function() {
    let name = "test scenario. checking if everything works"
    let firstAgentParams = generateParams([0.3,0.3,0.4], 100, 0.9, 2)
    let firstAgentInitialState = {
      belief: [undefined, [2,2,2]],
      mentalEstimations: [undefined, [Delta({v: 0})]],
      metaParamsEstimations: {
        alpha: [undefined, Categorical({vs: [100]})],
        lookAhead: [undefined, Categorical({vs: [2]})],
        discountFactor: [undefined, Categorical({vs: [0.9]})]
      }
    }
    let firstAgent = {
      params: firstAgentParams,
      initialState: firstAgentInitialState
    }
    let secondAgentParams = generateParams([0.3,0.3,0.4], 100, 0.9, 2)
    let secondAgentInitialState = {
      belief: [[2,2,2], undefined],
      mentalEstimations: [[Delta({v: "irrelevant"})], undefined], // an array of mental estimations (where each estimation is a distribution)
      metaParamsEstimations: {
        alpha: [Categorical({vs: [100]}), undefined],
        lookAhead: [Categorical({vs: [2]}), undefined],
        discountFactor: [Categorical({vs: [0.9]}), undefined]
      }
    }
    let secondAgent = {
      params: secondAgentParams,
      initialState: secondAgentInitialState
    }
    let agents = [firstAgent, secondAgent]
    return {name, agents, options}
  }

  return [getTestScenario()]
}

let getPaperScenarios = function() {
  let setups = [
    {
      name: "setting inspired by paper; accurate initial beliefs",
      p1: {
        goalCoeffs: [0.2,0.35,0.45],
        belief: [2,1,2]
      },
      p2: {
        goalCoeffs: [0.4,0.2,0.4],
        belief: [1,1.5,2]
      }
    },
    {
      name: "setting inspired by paper; uniform initial beliefs",
      p1: {
        goalCoeffs: [0.2,0.35,0.45],
        belief: [1,1,1]
      },
      p2: {
        goalCoeffs: [0.4,0.2,0.4],
        belief: [1,1,1]
      }
    },
    {
      name: "setting inspired by paper; inaccurate initial beliefs",
      p1: {
        goalCoeffs: [0.2,0.35,0.45],
        belief: [1,3,1]
      },
      p2: {
        goalCoeffs: [0.4,0.2,0.4],
        belief: [3,2,1]
      }
    }
  ]
  // let name = "scenario inspired by the setting from GPS paper"
  let gameSpecificParams = {
    bias: 1
  }

  let scenarios = map(function(setup) {
    let name = setup.name
    let p1Params = generateParams(setup.p1.goalCoeffs, 30, 1, 1)
    let p1InitialState = {
      belief: [undefined, setup.p1.belief],
      mentalEstimations: [undefined, [Delta({v: 0})]],
      metaParamsEstimations: {
        alpha: [undefined, Categorical({vs: [10]})],
        lookAhead: [undefined, Categorical({vs: [2]})],
        discountFactor: [undefined, Categorical({vs: [1]})]
      }
    }
    let p1 = {
      params: p1Params,
      initialState: p1InitialState
    }
    let p2Params = generateParams(setup.p2.goalCoeffs, 10, 1, 2)
    let p2InitialState = {
      belief: [setup.p2.belief, undefined],
      mentalEstimations: [[Delta({v: "irrelevant"})], undefined], // an array of mental estimations (where each estimation is a distribution)
      metaParamsEstimations: {
        alpha: [Categorical({vs: [10]}), undefined],
        lookAhead: [Categorical({vs: [1]}), undefined],
        discountFactor: [Categorical({vs: [1]}), undefined]
      }
    }
    let p2 = {
      params: p2Params,
      initialState: p2InitialState
    }
    let agents = [p1, p2]
    return {name, agents, options, gameSpecificParams}
  }, setups)
  return scenarios
}

let getVaryLookaheadScenarios = function() {
  let options = {
    horizon: 20,
    beliefRepresentation: 'dirichlet'
  }
  let goalCoeffs = [0.35,0.6,0.05]
  let setups = [
    {
      name: "small lookahead",
      p1: {
        goalCoeffs,
        belief: [2,1,2],
        lookAhead: 1
      },
      p2: {
        goalCoeffs: [0.4,0.2,0.4],
        belief: [1,1.5,2]
      }
    },
    {
      name: "bigger lookahead",
      p1: {
        goalCoeffs,
        belief: [2,1,2],
        lookAhead: 3
      },
      p2: {
        goalCoeffs: [0.4,0.2,0.4],
        belief: [1,1.5,2]
      }
    },
    {
      name: "big lookahead",
      p1: {
        goalCoeffs,
        belief: [2,1,2],
        lookAhead: 5
      },
      p2: {
        goalCoeffs: [0.4,0.2,0.4],
        belief: [1,1.5,2]
      }
    }
  ]
  // let name = "scenario inspired by the setting from GPS paper"
  let gameSpecificParams = {
    bias: 1
  }

  let scenarios = map(function(setup) {
    let name = setup.name
    let p1Params = generateParams(setup.p1.goalCoeffs, 30, 1, setup.p1.lookAhead)
    let p1InitialState = {
      belief: [undefined, setup.p1.belief],
      mentalEstimations: [undefined, [Delta({v: 0})]],
      metaParamsEstimations: {
        alpha: [undefined, Categorical({vs: [10]})],
        lookAhead: [undefined, Categorical({vs: [2]})],
        discountFactor: [undefined, Categorical({vs: [1]})]
      }
    }
    let p1 = {
      params: p1Params,
      initialState: p1InitialState
    }
    let p2Params = generateParams(setup.p2.goalCoeffs, 10, 1, 2)
    let p2InitialState = {
      belief: [setup.p2.belief, undefined],
      mentalEstimations: [[Delta({v: "irrelevant"})], undefined], // an array of mental estimations (where each estimation is a distribution)
      metaParamsEstimations: {
        alpha: [Categorical({vs: [10]}), undefined],
        lookAhead: [Categorical({vs: [1]}), undefined],
        discountFactor: [Categorical({vs: [1]}), undefined]
      }
    }
    let p2 = {
      params: p2Params,
      initialState: p2InitialState
    }
    let agents = [p1, p2]
    return {name, agents, options, gameSpecificParams}
  }, setups)
  return scenarios
}

/** Run simulations */
let scenarios = getScenarios().slice(1)
// simulateScenarios(scenarios, makeBraveryGame, ["p1", "p2"], callbacks)
// simulateScenarios(getPaperScenarios(), makeBraveryGame, ["p1", "p2"], callbacks)
let rewards = mapN(function(i) {
  let trajectories =
    simulateScenarios(getVaryLookaheadScenarios(), makeBraveryGame, ["p1", "p2"], callbacks)
  return map(function(trajectory) {
    return trajectory[trajectory.length - 1][1]
  }, trajectories)
}, 5)
display(toString(rewards))

let rewardsSum = reduceL(function(acc, rews) {
  return map2(function(p1, p2) {
    return arrayAddElementWise(p1,p2)
  }, acc, rews)
}, [[0,0],[0,0],[0,0]], rewards)
let rewardsAvg = map(function(pair) {
  return map(function (x) { return x / 5 }, pair)
}, rewardsSum)

display(rewardsAvg)