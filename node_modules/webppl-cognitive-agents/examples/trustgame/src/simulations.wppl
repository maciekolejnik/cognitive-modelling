/** Simulations for the trust game */

/** To run:
  $ webppl examples/trustgame/src/simulations.wppl --require . --require
  examples/trustgame [--] [--help] [--experiment <experimentID>] [--scenario
  <scnearioID>] [--runs <numberOfRuns>] [--reps <numberOfReps>]
 */


/** Callbacks */
let printTrusts = function(game, agents, state, names) {
  let f = function(agentID, agent) {
    let mentalState = agent.mentalState
    let mentalRewards = agent.mentalRewards
    let trust = mentalState(state)[0]
    let trustEstimation = mentalRewards(state)[0]
    return names[agentID] + ":\n  trust: " + trust +
      "\n  trust estimation: " + trustEstimation
  }
  display(mapIndexed(f, agents).join("\n"))
}

let callbacks = {
  periodic: printTrusts
}

/** Returns an array of agent setups where meta params and meta param
 * estimations are fixed to (100, 0.8, 2/3)
 */
let getAgents = function(goalCoeffs, beliefs, trustExps) {
  let aliceParams = generateParams(goalCoeffs[0], 100, 0.8, 2)
  let aliceInitialStateTmp =
    generateInitialState(0, 2, 100, 0.8, 3)
  let aliceInitialState =
    extend(aliceInitialStateTmp
      ,
      {
        belief: arrayReplace(aliceInitialStateTmp.belief, 1, beliefs[0]),
        mentalEstimations:
          arrayReplace(aliceInitialStateTmp.mentalEstimations, 1, [Delta({v: trustExps[0]})])
      }
    )
  let bobParams = generateParams(goalCoeffs[0], 100, 0.8, 3)
  let bobInitialStateTmp =
    generateInitialState(1, 2, 100, 0.8, 2)
  let bobInitialState =
    extend(bobInitialStateTmp
      ,
      {
        belief: arrayReplace(bobInitialStateTmp.belief, 0, beliefs[0]),
        mentalEstimations:
          arrayReplace(bobInitialStateTmp.mentalEstimations, 0, [Delta({v: trustExps[1]})])
      }
    )
  let alice = {
    params: aliceParams,
    initialState: aliceInitialState
  }
  let bob = {
    params: bobParams,
    initialState: bobInitialState
  }
  let agents = [alice, bob]
  return agents
}

let names = ['alice','bob']

/* Setup game structure */
let gameSpecificParams = {
  endowments : {
    'investor': 4,
    'investee': 0
  },
  k: 2
}

let options = {
  horizon: 10,
  beliefRepresentation: 'dirichlet'
}

let testExperiment = function() {
  /**
   * This is a basic scenario with standard parameters
   */
  let getScenarioBasic = function() {
    let name = "Basic (high trust, high trustworthiness)"
    let bobParams = generateParams([0.3,0.7], 100, 0.8, 3)
    let bobInitialStateTmp =
      generateInitialState(1, 2, 100, 0.8, 2)
    let bobInitialState =
      extend(bobInitialStateTmp
        ,
        {
          belief: arrayReplace(bobInitialStateTmp.belief, 0, [1,3]),
          mentalEstimations:
            arrayReplace(bobInitialStateTmp.mentalEstimations, 0, [Delta({v: 0.7})])
        }
        )
    let aliceParams = generateParams([0.3,0.7], 100, 0.8, 2)
    let aliceInitialStateTmp =
      generateInitialState(0, 2, 100, 0.8, 3)
    let aliceInitialState =
      extend(aliceInitialStateTmp
        ,
        {
          belief: arrayReplace(aliceInitialStateTmp.belief, 1, [1,3]),
          mentalEstimations:
            arrayReplace(aliceInitialStateTmp.mentalEstimations, 1, [Delta({v: 0.7})])
        }
      )
    let alice = {
      params: aliceParams,
      initialState: aliceInitialState
    }
    let bob = {
      params: bobParams,
      initialState: bobInitialState
    }
    let agents = [alice, bob]
    return {name, agents, options, gameSpecificParams}
  }

  let getScenarioWeird = function() {
    let name = "this scenario was causing trust dynamics to fail before"
    let bobParams = generateParams([0.1767,0.8233], 100, 0.8, 3)
    let bobInitialStateTmp =
      generateInitialState(1, 2, 100, 0.8, 2)
    let bobInitialState =
      extend(bobInitialStateTmp
        ,
        {
          belief: arrayReplace(bobInitialStateTmp.belief, 0, [2,2]),
          mentalEstimations:
            arrayReplace(bobInitialStateTmp.mentalEstimations, 0, [Delta({v: 0.9602})])
        }
      )
    let aliceParams = generateParams([0.1767,0.8233], 100, 0.8, 2)
    let aliceInitialStateTmp =
      generateInitialState(0, 2, 100, 0.8, 3)
    let aliceInitialState =
      extend(aliceInitialStateTmp
        ,
        {
          belief: arrayReplace(aliceInitialStateTmp.belief, 1, [2,2]),
          mentalEstimations:
            arrayReplace(aliceInitialStateTmp.mentalEstimations, 1, [Delta({v: 0.8192})])
        }
      )
    let alice = {
      params: aliceParams,
      initialState: aliceInitialState
    }
    let bob = {
      params: bobParams,
      initialState: bobInitialState
    }
    let agents = [alice, bob]
    return {name, agents, options, gameSpecificParams}
  }

  let scenarios = [getScenarioBasic(), getScenarioWeird()]

  return {
    name: "testExperiment",
    desc: "random collection of test scenarios",
    scenarios,
    names,
    callbacks
  }
}()

let varyTrustExperiment = function() {

  /** Auxiliary */
  let computeAverageTransfers = function(scenarioTrajectories) {
    /** we know scenarioTrajectories should only have one element since
     * we run each scenario once */
    let avgInvest = listMean(map(function(x) { return x[1]},
      filter(function(x) {return _.isEqual(x[0].turn, 'investee')},
        scenarioTrajectories[0])))
    let avgRet = listMean(map(function(x) { return x[1]},
      filter(function(x) {return _.isEqual(x[0].turn, 'investor')},
        scenarioTrajectories[0])))
    return [avgInvest, avgRet]
  }

  let configurations = [
    ["Very low trust", [4,1]],
    ["Low trust", [3,2]],
    ["Medium trust", [2,2]],
    ["High trust", [2,3]],
    ["Very high trust", [1,4]]
  ]

  let scenarios = map(function(config) {
    return {
      name: config[0]
    }
  }, configurations)

  let run = function(params) {
    let reps = params.reps || 20
    assertHasType(INT_TYPE, reps, "varyTrustExperiment: run(): " +
      "reps has wrong type, expected INT, found: " + reps)
    assert(reps > 0, "varyTrustExperiment: run(): reps should " +
      "be a positive integer; found: " + reps)
    let getSetTrustScenarios = function(name, initialBelief) {
      let arrayOfAgentsConfigurations = repeat(reps, function() {
        let a = uniform(0,1)
        let b = uniform(0,1)
        let beliefs = [initialBelief,initialBelief]
        let trustExps = [uniform(0,1), uniform(0,1)]
        return getAgents([[a, 1-a], [b,1-b]], beliefs, trustExps)
      })
      return map(function(agents) {
        return {name, agents, options, gameSpecificParams}
      }, arrayOfAgentsConfigurations)
    }

    let averageTransfers = reduceL(function(acc, config) {
      let scenarios = getSetTrustScenarios(config[0], config[1])
      let trajectories = simulateScenarios(
        scenarios, makeTrustCSMG, ['alice','bob'], callbacks)
      let averages = map(computeAverageTransfers, trajectories)
      let avgInvest = listMean(map(fst, averages))
      let avgReturn = listMean(map(snd, averages))
      let summary = [config[0], [avgInvest, avgReturn]]
      return acc.concat([summary])
    }, [], configurations)

    reduceL(function(acc, avgTransfers) {
      display(avgTransfers[0] + ": " + avgTransfers[1][0] + " on average " +
        "invested, " + avgTransfers[1][1] + " on average returned")
    }, [], averageTransfers)
  }

  let getParams = function(argv) {
    let repsStr = assertDefined(argv.reps, "varyTrustExperiment: " +
      "getParams(): --reps parameter required, but not found!")
    let reps = parseInt(repsStr)
    assert(reps > 0, "varyTrustExperiment: getParams(): reps " +
      "must be positive")
    return {
      reps
    }
  }

  return {
    name: "varyTrustExperiment",
    desc: "This experiment investigates how initial trust affects" +
      " amounts sent - this is H2 from QEST paper." +
      "\nThe scenarios are categorized by initial level of trust between" +
      " agents (both agents start with the same belief)" +
      "\nNote that this " +
      "is a custom experiment and it requires [--reps <numberOfReps>] " +
      "passed in command line - this is the number of repetitions each " +
      "scenario will be run (with random agents' characteristics). If not " +
      "passed, it defaults to 20",
    run,
    getParams,
    scenarios
  }
}()

let conmanNoncognitiveExperiment = function() {

  /** conman will be a non cognitive agent who uses a strategy.
   * the strategy will be to make high returns initially if the
   * investments are low, but when investments get high, keep the
   * money. this strategy is encoded below */
  let conmanReturn = function(state) {
    let lastInvestment = state.investments[0]
    let iteration = state.investments.length
    if (lastInvestment >= 3) return 0
    if (iteration <= 2) return 2 * lastInvestment
    return Math.max(0, lastInvestment - 1)
  }

  let run = function() {
    let aliceParams = generateParams([0.5,0.5], 100, 0.8, 2)
    let aliceInitialStateTmp =
      generateInitialState(0, 2, 100, 0.8, 3)
    let aliceInitialState =
      extend(aliceInitialStateTmp
        ,
        {
          belief: arrayReplace(aliceInitialStateTmp.belief, 1, [2,2]),
          mentalEstimations:
            arrayReplace(aliceInitialStateTmp.mentalEstimations, 1, [Delta({v: 0.7})])
        }
      )
    let gameSetup = makeTrustCSMG(gameSpecificParams)
    let game = makeCSMG(gameSetup, options)
    let turn = game.API.turn
    let transitionFn = game.transitionFn
    let alice = makeAgent(aliceParams, 0, aliceInitialState, game)
    let act = alice.act
    let simul = function(state, stepsLeft) {
      if (stepsLeft > 0) {
        let actionTaker = turn(state)
        let action = (actionTaker === 0) ? sample(act(state)) : conmanReturn(state)
        explain('\nAction computed: ' + action)
        let nextState = sample(transitionFn(state, action))
        return [[state, action]].concat(simul(nextState, stepsLeft - 1))
      }
      return []
    }
    let initialState = game.initialState
    let trajectory = simul(initialState, options.horizon)
    display(map(snd, trajectory))
  }

  let scenarios = [{name: "bob has a strategy, alice is uniform"}]

  return {
    name: "conmanNoncognitiveExperiment",
    desc: "This experiment studies behaviour of a cognitive agent (Alice)" +
      " when Bob is a (non-cognitive) con man, which means Bob tries to " +
      "trick Alice into trusting him and then keep a lot of money",
    run,
    scenarios
  }
}()

let conmanCognitiveExperiment = function() {

  /** bob knows game lasts for 3 rounds */
  let gameSpecificParams = extend(gameSpecificParams,
    {
      horizon: {
        investee: 3
      }
    })

  let options = extend(options,
    {
      horizon: 6
    })

  let scenarios = function() {
    /** Now we check whether a fair agent can punish a con man who tries
     * to take advantage of them. H3 alternative */
    let aliceParams = generateParams([0.5,0,0.5], 100, 0.8, 2)
    let aliceInitialStateTmp =
      generateInitialState(0, 2, 100, 0.8, 3)
    let aliceInitialState =
      extend(aliceInitialStateTmp
        ,
        {
          belief: arrayReplace(aliceInitialStateTmp.belief, 1, [1,1]),
          mentalEstimations:
            arrayReplace(aliceInitialStateTmp.mentalEstimations, 1, [Delta({v: 0.75})])
        }
      )
    let bobParams = generateParams([1,0], 100, 1, 5)
    let bobInitialStateTmp =
      generateInitialState(1, 2, 100, 0.8, 1)
    let bobInitialState =
      extend(bobInitialStateTmp
        ,
        {
          belief: arrayReplace(bobInitialStateTmp.belief, 0, [1,10,1]),
          mentalEstimations:
            arrayReplace(bobInitialStateTmp.mentalEstimations, 0, [Delta({v: 0.5})])
        }
      )
    let alice = {
      params: aliceParams,
      initialState: aliceInitialState
    }
    let bob = {
      params: bobParams,
      initialState: bobInitialState
    }
    let agents = [alice, bob]
    let name = "H3 both cognitive"
    let scenario = { name, agents, options, gameSpecificParams}
    return [ scenario ]
    // simulateScenarios([scenario], makeTrustCSMG, ['alice', 'bob'], callbacks)
  }()

  return {
    name: "conmanCognitiveExperiment",
    desc: "This experiment attempts to recreate con man behaviour using " +
      "the framework and finding out how the other player reacts." +
      " The idea is to make Bob only care about money (goalCoeffs = [1,0]) " +
      "and encode him knowing that the game will last 3 rounds",
    scenarios,
    callbacks,
    names
  }
}()

// let paperExperiments = [
//   {
//     run: function() {
//       /** First comes an experiment that investigates how initial trust affects
//        * amounts sent - this is H2 from QEST paper */
//       let configurations = [
//         ["Very low trust", [4,1]],
//         ["Low trust", [3,2]],
//         ["Medium trust", [2,2]],
//         ["High trust", [2,3]],
//         ["Very high trust", [1,4]]
//       ]
//
//       let averageTransfers = reduceL(function(acc, config) {
//         let trajectories = simulateScenarios(getSetTrustScenarios(config[0], config[1]), makeTrustCSMG, ['alice','bob'], callbacks)
//         let averages = map(computeAverageTransfers, trajectories)
//         let avgInvest = listMean(map(fst, averages))
//         let avgReturn = listMean(map(snd, averages))
//         let summary = [config[0], [avgInvest, avgReturn]]
//         return acc.concat([summary])
//       }, [], configurations)
//
//       reduceL(function(acc, avgTransfers) {
//         display(avgTransfers[0] + ": " + avgTransfers[1][0] + " on average " +
//           "invested, " + avgTransfers[1][1] + " on average returned")
//       }, [], averageTransfers)
//     }
//   },
//
//   {
//     run: function() {
//       /** Now we check whether a fair agent can punish a con man who tries
//        * to take advantage of them. H3 */
//
//       /** conman will be a non cognitive agent who uses a strategy.
//        * the strategy will be to make high returns initially if the
//        * investments are low, but when investments get high, keep the
//        * money. this strategy is encoded below */
//       let conmanReturn = function(state) {
//         let lastInvestment = state.investments[0]
//         let iteration = state.investments.length
//         if (lastInvestment >= 3) return 0
//         if (iteration <= 2) return 2 * lastInvestment
//         return lastInvestment - 1
//       }
//       let aliceParams = generateParams([0.5,0.5], 100, 0.8, 2)
//       let aliceInitialStateTmp =
//         generateInitialState(0, 2, 100, 0.8, 3)
//       let aliceInitialState =
//         extend(aliceInitialStateTmp
//           ,
//           {
//             belief: arrayReplace(aliceInitialStateTmp.belief, 1, [2,2]),
//             mentalEstimations:
//               arrayReplace(aliceInitialStateTmp.mentalEstimations, 1, [Delta({v: 0.7})])
//           }
//         )
//       let gameSetup = makeTrustCSMG(gameSpecificParams)
//       let game = makeCSMG(gameSetup, options)
//       let turn = game.API.turn
//       let transitionFn = game.transitionFn
//       let alice = makeAgent(aliceParams, 0, aliceInitialState, game)
//       let act = alice.act
//       let simul = function(state, stepsLeft) {
//         if (stepsLeft > 0) {
//           let actionTaker = turn(state)
//           let action = (actionTaker === 0) ? sample(act(state)) : conmanReturn(state)
//           explain('\nAction computed: ' + action)
//           let nextState = sample(transitionFn(state, action))
//           return [[state, action]].concat(simul(nextState, stepsLeft - 1))
//         }
//         return []
//       }
//       let initialState = game.initialState
//       simul(initialState, options.horizon)
//     }
//   },
//
//   {
//     run: function() {
//       /** Now we check whether a fair agent can punish a con man who tries
//        * to take advantage of them. H3 alternative */
//       let aliceParams = generateParams([0.5,0.5], 100, 0.8, 2)
//       let aliceInitialStateTmp =
//         generateInitialState(0, 2, 100, 0.8, 3)
//       let aliceInitialState =
//         extend(aliceInitialStateTmp
//           ,
//           {
//             belief: arrayReplace(aliceInitialStateTmp.belief, 1, [1,1]),
//             mentalEstimations:
//               arrayReplace(aliceInitialStateTmp.mentalEstimations, 1, [Delta({v: 0.5})])
//           }
//         )
//       let bobParams = generateParams([1,0], 100, 0.8, 5)
//       let bobInitialStateTmp =
//         generateInitialState(1, 2, 100, 0.8, 2)
//       let bobInitialState =
//         extend(bobInitialStateTmp
//           ,
//           {
//             belief: arrayReplace(bobInitialStateTmp.belief, 0, [2,2]),
//             mentalEstimations:
//               arrayReplace(bobInitialStateTmp.mentalEstimations, 0, [Delta({v: 0.5})])
//           }
//         )
//       let alice = {
//         params: aliceParams,
//         initialState: aliceInitialState
//       }
//       let bob = {
//         params: bobParams,
//         initialState: bobInitialState
//       }
//       let agents = [alice, bob]
//       let name = "H3 both cognitive"
//       let scenario = { name, agents, options, gameSpecificParams}
//       simulateScenarios([scenario], makeTrustCSMG, ['alice', 'bob'], callbacks)
//     }
//   }
// ]

let experiments = [testExperiment, varyTrustExperiment,
  conmanNoncognitiveExperiment, conmanCognitiveExperiment]

processCommandline(makeTrustCSMG, experiments)



